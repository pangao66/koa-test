{"version":3,"sources":["../node_modules/.pnpm/registry.npmmirror.com+tsup@6.7.0_6qtx7vkbdhwvdm4crzlegk4mvi/node_modules/tsup/assets/esm_shims.js","../src/index.ts","../src/chatgpt/index.ts","../src/utils/index.ts","../src/utils/is.ts"],"sourcesContent":["// Shim globals in esm bundle\nimport { fileURLToPath } from 'url'\nimport path from 'path'\n\nconst getFilename = () => fileURLToPath(import.meta.url)\nconst getDirname = () => path.dirname(getFilename())\n\nexport const __dirname = /* @__PURE__ */ getDirname()\nexport const __filename = /* @__PURE__ */ getFilename()\n","import Koa from \"koa\";\nimport koaBodyParser from \"koa-bodyparser\";\nimport Router from \"koa-router\";\nimport KoaStatic from \"koa-static\";\nimport path from \"path\";\nimport { fileURLToPath } from \"url\";\nimport type { RequestProps } from \"./types\";\nimport type { ChatMessage } from \"chatgpt\";\nimport { PassThrough } from \"stream\";\nimport { chatConfig, chatReplyProcess, currentModel } from \"./chatgpt\";\nimport { isNotEmptyString } from \"./utils/is\";\n\n\nconst app = new Koa();\nconst staticPath = \"../static\";\n// console.log(__dirname)\n// const __filename = fileURLToPath(import.meta.url);\n// const __dirname = path.dirname(__filename);\napp.use(KoaStatic(path.join(__dirname, staticPath)));\nconst router = new Router();\nrouter.get(\"/\", async (ctx) => {\n  ctx.body = {\n    data: \"1234\",\n  };\n});\n// SSE 请求，不返回标准 JSON，而是 UTF-8 文本\nconst CLOSE_MARK_MSG = \"--dev-zuo[DONE]dev-zuo--\";\nrouter.post(\"/chat-process\", async (ctx, next) => {\n  ctx.set({\n    \"Content-Type\": \"text/event-stream\",\n    \"Cache-Control\": \"no-cache\",\n    Connection: \"keep-alive\",\n  });\n  const steamData = new PassThrough();\n  ctx.body = steamData;\n  try {\n    const {\n      prompt,\n      options = {},\n      systemMessage,\n      temperature,\n      top_p,\n    } = ctx.request.body as RequestProps;\n    let firstChunk = true;\n    // const res = ctx.res\n    const res = await chatReplyProcess({\n      message: prompt,\n      lastContext: options,\n      process: (chat: ChatMessage) => {\n        console.log(chat)\n        // res.write(firstChunk ? JSON.stringify(chat) : `\\n${JSON.stringify(chat)}`)\n        // ctx.body = passThrough;\n        // res.write(firstChunk ? JSON.stringify(chat) : `\\n${JSON.stringify(chat)}`)\n        // stream.write(firstChunk ? JSON.stringify(chat) : `\\n${JSON.stringify(chat)}`)\n        // ctx.body = firstChunk ? JSON.stringify(chat) : `\\n${JSON.stringify(chat)}`\n        // passThrough.write(\n        //   firstChunk ? JSON.stringify(chat) : `\\n${JSON.stringify(chat)}`\n        // );\n        steamData.write(`data:${JSON.stringify(chat.text)}\\n\\n`);\n        // {\"role\":\"assistant\",\"id\":\"chatcmpl-74YzUfLNYFwbATCpNNEyg55UeAwi7\",\"parentMessageId\":\"9a9fd7a2-8b9b-4e40-96ab-176bf80f1f43\",\"text\":\"您好！\",\"detail\":{\"id\":\"chatcmpl-74YzUfLNYFwbATCpNNEyg55UeAwi7\",\"object\":\"chat.completion.chunk\",\"created\":1681322172,\"model\":\"gpt-3.5-turbo-0301\",\"choices\":[{\"delta\":{},\"index\":0,\"finish_reason\":\"stop\"}]}}\n        if (chat.detail.choices[0].finish_reason === \"stop\") {\n          console.log(\"响应已结束\", chat.text); // print the full text at the end\n          steamData.write(`data:${CLOSE_MARK_MSG}\\n\\n`);\n          steamData.end();\n        }\n        firstChunk = false;\n      },\n      systemMessage,\n      temperature,\n      top_p,\n    });\n  } catch (error) {\n    ctx.body = error;\n  } finally {\n    // ctx.end()\n    next();\n  }\n});\n// //\nrouter.post(\"/config\", async (ctx) => {\n  try {\n    const response = await chatConfig();\n    // res.send(response)\n    ctx.body = response;\n  } catch (error) {\n    // res.send(error)\n    ctx.body = error;\n  }\n});\n\nrouter.post(\"/session\", async (ctx) => {\n  try {\n    const AUTH_SECRET_KEY = process.env.AUTH_SECRET_KEY;\n    const hasAuth = isNotEmptyString(AUTH_SECRET_KEY);\n    // res.send({ status: 'Success', message: '', data: { auth: hasAuth, model: currentModel() } })\n    ctx.body = {\n      status: \"Success\",\n      message: \"\",\n      data: { auth: hasAuth, model: currentModel() },\n    };\n  } catch (error) {\n    // res.send({ status: 'Fail', message: error.message, data: null })\n    ctx.body = { status: \"Fail\", message: error.message, data: null };\n  }\n});\n\nrouter.post(\"/verify\", async (ctx, next) => {\n  try {\n    const { token } = ctx.request.body as { token: string };\n    if (!token) throw new Error(\"Secret key is empty\");\n\n    if (process.env.AUTH_SECRET_KEY !== token)\n      throw new Error(\"密钥无效 | Secret key is invalid\");\n\n    // res.send({ status: 'Success', message: 'Verify successfully', data: null })\n    ctx.body = {\n      status: \"Success\",\n      message: \"Verify successfully\",\n      data: null,\n    };\n  } catch (error) {\n    // res.send({ status: 'Fail', message: error.message, data: null })\n    ctx.body = { status: \"Fail\", message: error.message, data: null };\n  }\n});\nconst home = new Router();\nhome.get(\"/test\", async (ctx) => {\n  const res = ctx.res;\n  ctx.status = 200;\n  res.setHeader(\"Content-Type\", \"text/html\");\n  res.setHeader('Cache-Control', 'no-cache, no-transform')\n  res.setHeader('X-Accel-Buffering', 'no')\n  res.write(`start<br>`);\n  return new Promise<void>(resolve => {\n    let i = 0,\n      total = 5;\n    while (i <= total) {\n      (function (i) {\n        setTimeout(() => {\n          if (i === total) {\n            resolve();\n            res.end();\n          } else {\n            res.write(`${i}<br>`);\n          }\n        }, i * 1000);\n      })(i);\n      i++;\n    }\n  });\n});\nconst rootRouter = new Router();\n// // 装载所有子路由\n// let router = new Router()\nrootRouter.use(\"/home\", home.routes(), home.allowedMethods());\nrootRouter.use(\"/api\", router.routes(), router.allowedMethods());\napp.use(koaBodyParser());\n// router.use('/api', router.routes(), router.allowedMethods())\n// 加载路由中间件\napp.use(rootRouter.routes()).use(rootRouter.allowedMethods());\napp.listen(process.env.PORT || 9020, () => {\n  console.log(\"启动了\");\n});\n","import * as dotenv from 'dotenv'\nimport 'isomorphic-fetch'\nimport type { ChatGPTAPIOptions, ChatMessage, SendMessageOptions } from 'chatgpt'\nimport { ChatGPTAPI, ChatGPTUnofficialProxyAPI } from 'chatgpt'\nimport { SocksProxyAgent } from 'socks-proxy-agent'\nimport httpsProxyAgent from 'https-proxy-agent'\nimport fetch from 'node-fetch'\nimport { sendResponse } from '../utils'\nimport { isNotEmptyString } from '../utils/is'\nimport type { ApiModel, ChatContext, ChatGPTUnofficialProxyAPIOptions, ModelConfig } from '../types'\nimport type { RequestOptions, SetProxyOptions, UsageResponse } from './types'\n\nconst { HttpsProxyAgent } = httpsProxyAgent\n\ndotenv.config()\n\nconst ErrorCodeMessage: Record<string, string> = {\n  401: '[OpenAI] 提供错误的API密钥 | Incorrect API key provided',\n  403: '[OpenAI] 服务器拒绝访问，请稍后再试 | Server refused to access, please try again later',\n  502: '[OpenAI] 错误的网关 |  Bad Gateway',\n  503: '[OpenAI] 服务器繁忙，请稍后再试 | Server is busy, please try again later',\n  504: '[OpenAI] 网关超时 | Gateway Time-out',\n  500: '[OpenAI] 服务器繁忙，请稍后再试 | Internal Server Error',\n}\n\nconst timeoutMs: number = !isNaN(+process.env.TIMEOUT_MS) ? +process.env.TIMEOUT_MS : 100 * 1000\nconst disableDebug: boolean = process.env.OPENAI_API_DISABLE_DEBUG === 'true'\n\nlet apiModel: ApiModel\nconst model = isNotEmptyString(process.env.OPENAI_API_MODEL) ? process.env.OPENAI_API_MODEL : 'gpt-3.5-turbo'\n\nif (!isNotEmptyString(process.env.OPENAI_API_KEY) && !isNotEmptyString(process.env.OPENAI_ACCESS_TOKEN))\n  throw new Error('Missing OPENAI_API_KEY or OPENAI_ACCESS_TOKEN environment variable')\n\nlet api: ChatGPTAPI | ChatGPTUnofficialProxyAPI\n\n(async () => {\n  // More Info: https://github.com/transitive-bullshit/chatgpt-api\n\n  if (isNotEmptyString(process.env.OPENAI_API_KEY)) {\n    const OPENAI_API_BASE_URL = process.env.OPENAI_API_BASE_URL\n\n    const options: ChatGPTAPIOptions = {\n      apiKey: process.env.OPENAI_API_KEY,\n      completionParams: { model },\n      debug: !disableDebug,\n    }\n\n    // increase max token limit if use gpt-4\n    if (model.toLowerCase().includes('gpt-4')) {\n      // if use 32k model\n      if (model.toLowerCase().includes('32k')) {\n        options.maxModelTokens = 32768\n        options.maxResponseTokens = 8192\n      }\n      else {\n        options.maxModelTokens = 8192\n        options.maxResponseTokens = 2048\n      }\n    }\n\n    if (isNotEmptyString(OPENAI_API_BASE_URL))\n      options.apiBaseUrl = `${OPENAI_API_BASE_URL}/v1`\n\n    setupProxy(options)\n\n    api = new ChatGPTAPI({ ...options })\n    apiModel = 'ChatGPTAPI'\n  }\n  else {\n    const options: ChatGPTUnofficialProxyAPIOptions = {\n      accessToken: process.env.OPENAI_ACCESS_TOKEN,\n      apiReverseProxyUrl: isNotEmptyString(process.env.API_REVERSE_PROXY) ? process.env.API_REVERSE_PROXY : 'https://bypass.churchless.tech/api/conversation',\n      model,\n      debug: !disableDebug,\n    }\n\n    setupProxy(options)\n\n    api = new ChatGPTUnofficialProxyAPI({ ...options })\n    apiModel = 'ChatGPTUnofficialProxyAPI'\n  }\n})()\n\nasync function chatReplyProcess(options: RequestOptions) {\n  const { message, lastContext, process, systemMessage, temperature, top_p } = options\n  try {\n    let options: SendMessageOptions = { timeoutMs }\n\n    if (apiModel === 'ChatGPTAPI') {\n      if (isNotEmptyString(systemMessage))\n        options.systemMessage = systemMessage\n      options.completionParams = { model, temperature, top_p }\n    }\n\n    if (lastContext != null) {\n      if (apiModel === 'ChatGPTAPI')\n        options.parentMessageId = lastContext.parentMessageId\n      else\n        options = { ...lastContext }\n    }\n\n    const response = await api.sendMessage(message, {\n      ...options,\n      onProgress: (partialResponse) => {\n        process?.(partialResponse)\n      },\n    })\n\n    return sendResponse({ type: 'Success', data: response })\n  }\n  catch (error: any) {\n    const code = error.statusCode\n    global.console.log(error)\n    if (Reflect.has(ErrorCodeMessage, code))\n      return sendResponse({ type: 'Fail', message: ErrorCodeMessage[code] })\n    return sendResponse({ type: 'Fail', message: error.message ?? 'Please check the back-end console' })\n  }\n}\n\nasync function fetchUsage() {\n  const OPENAI_API_KEY = process.env.OPENAI_API_KEY\n  const OPENAI_API_BASE_URL = process.env.OPENAI_API_BASE_URL\n\n  if (!isNotEmptyString(OPENAI_API_KEY))\n    return Promise.resolve('-')\n\n  const API_BASE_URL = isNotEmptyString(OPENAI_API_BASE_URL)\n    ? OPENAI_API_BASE_URL\n    : 'https://api.openai.com'\n\n  const [startDate, endDate] = formatDate()\n\n  // 每月使用量\n  const urlUsage = `${API_BASE_URL}/v1/dashboard/billing/usage?start_date=${startDate}&end_date=${endDate}`\n\n  const headers = {\n    'Authorization': `Bearer ${OPENAI_API_KEY}`,\n    'Content-Type': 'application/json',\n  }\n\n  const options = {} as SetProxyOptions\n\n  setupProxy(options)\n\n  try {\n    // 获取已使用量\n    const useResponse = await options.fetch(urlUsage, { headers })\n    if (!useResponse.ok)\n      throw new Error('获取使用量失败')\n    const usageData = await useResponse.json() as UsageResponse\n    const usage = Math.round(usageData.total_usage) / 100\n    return Promise.resolve(usage ? `$${usage}` : '-')\n  }\n  catch (error) {\n    global.console.log(error)\n    return Promise.resolve('-')\n  }\n}\n\nfunction formatDate(): string[] {\n  const today = new Date()\n  const year = today.getFullYear()\n  const month = today.getMonth() + 1\n  const lastDay = new Date(year, month, 0)\n  const formattedFirstDay = `${year}-${month.toString().padStart(2, '0')}-01`\n  const formattedLastDay = `${year}-${month.toString().padStart(2, '0')}-${lastDay.getDate().toString().padStart(2, '0')}`\n  return [formattedFirstDay, formattedLastDay]\n}\n\nasync function chatConfig() {\n  const usage = await fetchUsage()\n  const reverseProxy = process.env.API_REVERSE_PROXY ?? '-'\n  const httpsProxy = (process.env.HTTPS_PROXY || process.env.ALL_PROXY) ?? '-'\n  const socksProxy = (process.env.SOCKS_PROXY_HOST && process.env.SOCKS_PROXY_PORT)\n    ? (`${process.env.SOCKS_PROXY_HOST}:${process.env.SOCKS_PROXY_PORT}`)\n    : '-'\n  return sendResponse<ModelConfig>({\n    type: 'Success',\n    data: { apiModel, reverseProxy, timeoutMs, socksProxy, httpsProxy, usage },\n  })\n}\n\nfunction setupProxy(options: SetProxyOptions) {\n  if (isNotEmptyString(process.env.SOCKS_PROXY_HOST) && isNotEmptyString(process.env.SOCKS_PROXY_PORT)) {\n    const agent = new SocksProxyAgent({\n      hostname: process.env.SOCKS_PROXY_HOST,\n      port: process.env.SOCKS_PROXY_PORT,\n      userId: isNotEmptyString(process.env.SOCKS_PROXY_USERNAME) ? process.env.SOCKS_PROXY_USERNAME : undefined,\n      password: isNotEmptyString(process.env.SOCKS_PROXY_PASSWORD) ? process.env.SOCKS_PROXY_PASSWORD : undefined,\n    })\n    options.fetch = (url, options) => {\n      return fetch(url, { agent, ...options })\n    }\n  }\n  else if (isNotEmptyString(process.env.HTTPS_PROXY) || isNotEmptyString(process.env.ALL_PROXY)) {\n    const httpsProxy = process.env.HTTPS_PROXY || process.env.ALL_PROXY\n    if (httpsProxy) {\n      const agent = new HttpsProxyAgent(httpsProxy)\n      options.fetch = (url, options) => {\n        return fetch(url, { agent, ...options })\n      }\n    }\n  }\n  else {\n    options.fetch = (url, options) => {\n      return fetch(url, { ...options })\n    }\n  }\n}\n\nfunction currentModel(): ApiModel {\n  return apiModel\n}\n\nexport type { ChatContext, ChatMessage }\n\nexport { chatReplyProcess, chatConfig, currentModel }\n","interface SendResponseOptions<T = any> {\n  type: 'Success' | 'Fail'\n  message?: string\n  data?: T\n}\n\nexport function sendResponse<T>(options: SendResponseOptions<T>) {\n  if (options.type === 'Success') {\n    return Promise.resolve({\n      message: options.message ?? null,\n      data: options.data ?? null,\n      status: options.type,\n    })\n  }\n\n  // eslint-disable-next-line prefer-promise-reject-errors\n  return Promise.reject({\n    message: options.message ?? 'Failed',\n    data: options.data ?? null,\n    status: options.type,\n  })\n}\n","export function isNumber<T extends number>(value: T | unknown): value is number {\n  return Object.prototype.toString.call(value) === '[object Number]'\n}\n\nexport function isString<T extends string>(value: T | unknown): value is string {\n  return Object.prototype.toString.call(value) === '[object String]'\n}\n\nexport function isNotEmptyString(value: any): boolean {\n  return typeof value === 'string' && value.length > 0\n}\n\nexport function isBoolean<T extends boolean>(value: T | unknown): value is boolean {\n  return Object.prototype.toString.call(value) === '[object Boolean]'\n}\n\nexport function isFunction<T extends (...args: any[]) => any | void | never>(value: T | unknown): value is T {\n  return Object.prototype.toString.call(value) === '[object Function]'\n}\n"],"mappings":";AACA,SAAS,qBAAqB;AAC9B,OAAO,UAAU;AAEjB,IAAM,cAAc,MAAM,cAAc,YAAY,GAAG;AACvD,IAAM,aAAa,MAAM,KAAK,QAAQ,YAAY,CAAC;AAE5C,IAAM,YAA4B,2BAAW;;;ACPpD,OAAO,SAAS;AAChB,OAAO,mBAAmB;AAC1B,OAAO,YAAY;AACnB,OAAO,eAAe;AACtB,OAAOA,WAAU;AAIjB,SAAS,mBAAmB;;;ACR5B,YAAY,YAAY;AACxB,OAAO;AAEP,SAAS,YAAY,iCAAiC;AACtD,SAAS,uBAAuB;AAChC,OAAO,qBAAqB;AAC5B,OAAO,WAAW;;;ACAX,SAAS,aAAgB,SAAiC;AAC/D,MAAI,QAAQ,SAAS,WAAW;AAC9B,WAAO,QAAQ,QAAQ;AAAA,MACrB,SAAS,QAAQ,WAAW;AAAA,MAC5B,MAAM,QAAQ,QAAQ;AAAA,MACtB,QAAQ,QAAQ;AAAA,IAClB,CAAC;AAAA,EACH;AAGA,SAAO,QAAQ,OAAO;AAAA,IACpB,SAAS,QAAQ,WAAW;AAAA,IAC5B,MAAM,QAAQ,QAAQ;AAAA,IACtB,QAAQ,QAAQ;AAAA,EAClB,CAAC;AACH;;;ACbO,SAAS,iBAAiB,OAAqB;AACpD,SAAO,OAAO,UAAU,YAAY,MAAM,SAAS;AACrD;;;AFEA,IAAM,EAAE,gBAAgB,IAAI;AAErB,cAAO;AAEd,IAAM,mBAA2C;AAAA,EAC/C,KAAK;AAAA,EACL,KAAK;AAAA,EACL,KAAK;AAAA,EACL,KAAK;AAAA,EACL,KAAK;AAAA,EACL,KAAK;AACP;AAEA,IAAM,YAAoB,CAAC,MAAM,CAAC,QAAQ,IAAI,UAAU,IAAI,CAAC,QAAQ,IAAI,aAAa,MAAM;AAC5F,IAAM,eAAwB,QAAQ,IAAI,6BAA6B;AAEvE,IAAI;AACJ,IAAM,QAAQ,iBAAiB,QAAQ,IAAI,gBAAgB,IAAI,QAAQ,IAAI,mBAAmB;AAE9F,IAAI,CAAC,iBAAiB,QAAQ,IAAI,cAAc,KAAK,CAAC,iBAAiB,QAAQ,IAAI,mBAAmB;AACpG,QAAM,IAAI,MAAM,oEAAoE;AAEtF,IAAI;AAAA,CAEH,YAAY;AAGX,MAAI,iBAAiB,QAAQ,IAAI,cAAc,GAAG;AAChD,UAAM,sBAAsB,QAAQ,IAAI;AAExC,UAAM,UAA6B;AAAA,MACjC,QAAQ,QAAQ,IAAI;AAAA,MACpB,kBAAkB,EAAE,MAAM;AAAA,MAC1B,OAAO,CAAC;AAAA,IACV;AAGA,QAAI,MAAM,YAAY,EAAE,SAAS,OAAO,GAAG;AAEzC,UAAI,MAAM,YAAY,EAAE,SAAS,KAAK,GAAG;AACvC,gBAAQ,iBAAiB;AACzB,gBAAQ,oBAAoB;AAAA,MAC9B,OACK;AACH,gBAAQ,iBAAiB;AACzB,gBAAQ,oBAAoB;AAAA,MAC9B;AAAA,IACF;AAEA,QAAI,iBAAiB,mBAAmB;AACtC,cAAQ,aAAa,GAAG;AAE1B,eAAW,OAAO;AAElB,UAAM,IAAI,WAAW,EAAE,GAAG,QAAQ,CAAC;AACnC,eAAW;AAAA,EACb,OACK;AACH,UAAM,UAA4C;AAAA,MAChD,aAAa,QAAQ,IAAI;AAAA,MACzB,oBAAoB,iBAAiB,QAAQ,IAAI,iBAAiB,IAAI,QAAQ,IAAI,oBAAoB;AAAA,MACtG;AAAA,MACA,OAAO,CAAC;AAAA,IACV;AAEA,eAAW,OAAO;AAElB,UAAM,IAAI,0BAA0B,EAAE,GAAG,QAAQ,CAAC;AAClD,eAAW;AAAA,EACb;AACF,GAAG;AAEH,eAAe,iBAAiB,SAAyB;AACvD,QAAM,EAAE,SAAS,aAAa,SAAAC,UAAS,eAAe,aAAa,MAAM,IAAI;AAC7E,MAAI;AACF,QAAIC,WAA8B,EAAE,UAAU;AAE9C,QAAI,aAAa,cAAc;AAC7B,UAAI,iBAAiB,aAAa;AAChC,QAAAA,SAAQ,gBAAgB;AAC1B,MAAAA,SAAQ,mBAAmB,EAAE,OAAO,aAAa,MAAM;AAAA,IACzD;AAEA,QAAI,eAAe,MAAM;AACvB,UAAI,aAAa;AACf,QAAAA,SAAQ,kBAAkB,YAAY;AAAA;AAEtC,QAAAA,WAAU,EAAE,GAAG,YAAY;AAAA,IAC/B;AAEA,UAAM,WAAW,MAAM,IAAI,YAAY,SAAS;AAAA,MAC9C,GAAGA;AAAA,MACH,YAAY,CAAC,oBAAoB;AAC/B,QAAAD,WAAU,eAAe;AAAA,MAC3B;AAAA,IACF,CAAC;AAED,WAAO,aAAa,EAAE,MAAM,WAAW,MAAM,SAAS,CAAC;AAAA,EACzD,SACO,OAAP;AACE,UAAM,OAAO,MAAM;AACnB,WAAO,QAAQ,IAAI,KAAK;AACxB,QAAI,QAAQ,IAAI,kBAAkB,IAAI;AACpC,aAAO,aAAa,EAAE,MAAM,QAAQ,SAAS,iBAAiB,IAAI,EAAE,CAAC;AACvE,WAAO,aAAa,EAAE,MAAM,QAAQ,SAAS,MAAM,WAAW,oCAAoC,CAAC;AAAA,EACrG;AACF;AAEA,eAAe,aAAa;AAC1B,QAAM,iBAAiB,QAAQ,IAAI;AACnC,QAAM,sBAAsB,QAAQ,IAAI;AAExC,MAAI,CAAC,iBAAiB,cAAc;AAClC,WAAO,QAAQ,QAAQ,GAAG;AAE5B,QAAM,eAAe,iBAAiB,mBAAmB,IACrD,sBACA;AAEJ,QAAM,CAAC,WAAW,OAAO,IAAI,WAAW;AAGxC,QAAM,WAAW,GAAG,sDAAsD,sBAAsB;AAEhG,QAAM,UAAU;AAAA,IACd,iBAAiB,UAAU;AAAA,IAC3B,gBAAgB;AAAA,EAClB;AAEA,QAAM,UAAU,CAAC;AAEjB,aAAW,OAAO;AAElB,MAAI;AAEF,UAAM,cAAc,MAAM,QAAQ,MAAM,UAAU,EAAE,QAAQ,CAAC;AAC7D,QAAI,CAAC,YAAY;AACf,YAAM,IAAI,MAAM,4CAAS;AAC3B,UAAM,YAAY,MAAM,YAAY,KAAK;AACzC,UAAM,QAAQ,KAAK,MAAM,UAAU,WAAW,IAAI;AAClD,WAAO,QAAQ,QAAQ,QAAQ,IAAI,UAAU,GAAG;AAAA,EAClD,SACO,OAAP;AACE,WAAO,QAAQ,IAAI,KAAK;AACxB,WAAO,QAAQ,QAAQ,GAAG;AAAA,EAC5B;AACF;AAEA,SAAS,aAAuB;AAC9B,QAAM,QAAQ,oBAAI,KAAK;AACvB,QAAM,OAAO,MAAM,YAAY;AAC/B,QAAM,QAAQ,MAAM,SAAS,IAAI;AACjC,QAAM,UAAU,IAAI,KAAK,MAAM,OAAO,CAAC;AACvC,QAAM,oBAAoB,GAAG,QAAQ,MAAM,SAAS,EAAE,SAAS,GAAG,GAAG;AACrE,QAAM,mBAAmB,GAAG,QAAQ,MAAM,SAAS,EAAE,SAAS,GAAG,GAAG,KAAK,QAAQ,QAAQ,EAAE,SAAS,EAAE,SAAS,GAAG,GAAG;AACrH,SAAO,CAAC,mBAAmB,gBAAgB;AAC7C;AAEA,eAAe,aAAa;AAC1B,QAAM,QAAQ,MAAM,WAAW;AAC/B,QAAM,eAAe,QAAQ,IAAI,qBAAqB;AACtD,QAAM,cAAc,QAAQ,IAAI,eAAe,QAAQ,IAAI,cAAc;AACzE,QAAM,aAAc,QAAQ,IAAI,oBAAoB,QAAQ,IAAI,mBAC3D,GAAG,QAAQ,IAAI,oBAAoB,QAAQ,IAAI,qBAChD;AACJ,SAAO,aAA0B;AAAA,IAC/B,MAAM;AAAA,IACN,MAAM,EAAE,UAAU,cAAc,WAAW,YAAY,YAAY,MAAM;AAAA,EAC3E,CAAC;AACH;AAEA,SAAS,WAAW,SAA0B;AAC5C,MAAI,iBAAiB,QAAQ,IAAI,gBAAgB,KAAK,iBAAiB,QAAQ,IAAI,gBAAgB,GAAG;AACpG,UAAM,QAAQ,IAAI,gBAAgB;AAAA,MAChC,UAAU,QAAQ,IAAI;AAAA,MACtB,MAAM,QAAQ,IAAI;AAAA,MAClB,QAAQ,iBAAiB,QAAQ,IAAI,oBAAoB,IAAI,QAAQ,IAAI,uBAAuB;AAAA,MAChG,UAAU,iBAAiB,QAAQ,IAAI,oBAAoB,IAAI,QAAQ,IAAI,uBAAuB;AAAA,IACpG,CAAC;AACD,YAAQ,QAAQ,CAAC,KAAKC,aAAY;AAChC,aAAO,MAAM,KAAK,EAAE,OAAO,GAAGA,SAAQ,CAAC;AAAA,IACzC;AAAA,EACF,WACS,iBAAiB,QAAQ,IAAI,WAAW,KAAK,iBAAiB,QAAQ,IAAI,SAAS,GAAG;AAC7F,UAAM,aAAa,QAAQ,IAAI,eAAe,QAAQ,IAAI;AAC1D,QAAI,YAAY;AACd,YAAM,QAAQ,IAAI,gBAAgB,UAAU;AAC5C,cAAQ,QAAQ,CAAC,KAAKA,aAAY;AAChC,eAAO,MAAM,KAAK,EAAE,OAAO,GAAGA,SAAQ,CAAC;AAAA,MACzC;AAAA,IACF;AAAA,EACF,OACK;AACH,YAAQ,QAAQ,CAAC,KAAKA,aAAY;AAChC,aAAO,MAAM,KAAK,EAAE,GAAGA,SAAQ,CAAC;AAAA,IAClC;AAAA,EACF;AACF;AAEA,SAAS,eAAyB;AAChC,SAAO;AACT;;;ADxMA,IAAM,MAAM,IAAI,IAAI;AACpB,IAAM,aAAa;AAInB,IAAI,IAAI,UAAUC,MAAK,KAAK,WAAW,UAAU,CAAC,CAAC;AACnD,IAAM,SAAS,IAAI,OAAO;AAC1B,OAAO,IAAI,KAAK,OAAO,QAAQ;AAC7B,MAAI,OAAO;AAAA,IACT,MAAM;AAAA,EACR;AACF,CAAC;AAED,IAAM,iBAAiB;AACvB,OAAO,KAAK,iBAAiB,OAAO,KAAK,SAAS;AAChD,MAAI,IAAI;AAAA,IACN,gBAAgB;AAAA,IAChB,iBAAiB;AAAA,IACjB,YAAY;AAAA,EACd,CAAC;AACD,QAAM,YAAY,IAAI,YAAY;AAClC,MAAI,OAAO;AACX,MAAI;AACF,UAAM;AAAA,MACJ;AAAA,MACA,UAAU,CAAC;AAAA,MACX;AAAA,MACA;AAAA,MACA;AAAA,IACF,IAAI,IAAI,QAAQ;AAChB,QAAI,aAAa;AAEjB,UAAM,MAAM,MAAM,iBAAiB;AAAA,MACjC,SAAS;AAAA,MACT,aAAa;AAAA,MACb,SAAS,CAAC,SAAsB;AAC9B,gBAAQ,IAAI,IAAI;AAShB,kBAAU,MAAM,QAAQ,KAAK,UAAU,KAAK,IAAI;AAAA;AAAA,CAAO;AAEvD,YAAI,KAAK,OAAO,QAAQ,CAAC,EAAE,kBAAkB,QAAQ;AACnD,kBAAQ,IAAI,kCAAS,KAAK,IAAI;AAC9B,oBAAU,MAAM,QAAQ;AAAA;AAAA,CAAoB;AAC5C,oBAAU,IAAI;AAAA,QAChB;AACA,qBAAa;AAAA,MACf;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC;AAAA,EACH,SAAS,OAAP;AACA,QAAI,OAAO;AAAA,EACb,UAAE;AAEA,SAAK;AAAA,EACP;AACF,CAAC;AAED,OAAO,KAAK,WAAW,OAAO,QAAQ;AACpC,MAAI;AACF,UAAM,WAAW,MAAM,WAAW;AAElC,QAAI,OAAO;AAAA,EACb,SAAS,OAAP;AAEA,QAAI,OAAO;AAAA,EACb;AACF,CAAC;AAED,OAAO,KAAK,YAAY,OAAO,QAAQ;AACrC,MAAI;AACF,UAAM,kBAAkB,QAAQ,IAAI;AACpC,UAAM,UAAU,iBAAiB,eAAe;AAEhD,QAAI,OAAO;AAAA,MACT,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,MAAM,EAAE,MAAM,SAAS,OAAO,aAAa,EAAE;AAAA,IAC/C;AAAA,EACF,SAAS,OAAP;AAEA,QAAI,OAAO,EAAE,QAAQ,QAAQ,SAAS,MAAM,SAAS,MAAM,KAAK;AAAA,EAClE;AACF,CAAC;AAED,OAAO,KAAK,WAAW,OAAO,KAAK,SAAS;AAC1C,MAAI;AACF,UAAM,EAAE,MAAM,IAAI,IAAI,QAAQ;AAC9B,QAAI,CAAC;AAAO,YAAM,IAAI,MAAM,qBAAqB;AAEjD,QAAI,QAAQ,IAAI,oBAAoB;AAClC,YAAM,IAAI,MAAM,kDAA8B;AAGhD,QAAI,OAAO;AAAA,MACT,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,MAAM;AAAA,IACR;AAAA,EACF,SAAS,OAAP;AAEA,QAAI,OAAO,EAAE,QAAQ,QAAQ,SAAS,MAAM,SAAS,MAAM,KAAK;AAAA,EAClE;AACF,CAAC;AACD,IAAM,OAAO,IAAI,OAAO;AACxB,KAAK,IAAI,SAAS,OAAO,QAAQ;AAC/B,QAAM,MAAM,IAAI;AAChB,MAAI,SAAS;AACb,MAAI,UAAU,gBAAgB,WAAW;AACzC,MAAI,UAAU,iBAAiB,wBAAwB;AACvD,MAAI,UAAU,qBAAqB,IAAI;AACvC,MAAI,MAAM,WAAW;AACrB,SAAO,IAAI,QAAc,aAAW;AAClC,QAAI,IAAI,GACN,QAAQ;AACV,WAAO,KAAK,OAAO;AACjB,OAAC,SAAUC,IAAG;AACZ,mBAAW,MAAM;AACf,cAAIA,OAAM,OAAO;AACf,oBAAQ;AACR,gBAAI,IAAI;AAAA,UACV,OAAO;AACL,gBAAI,MAAM,GAAGA,QAAO;AAAA,UACtB;AAAA,QACF,GAAGA,KAAI,GAAI;AAAA,MACb,GAAG,CAAC;AACJ;AAAA,IACF;AAAA,EACF,CAAC;AACH,CAAC;AACD,IAAM,aAAa,IAAI,OAAO;AAG9B,WAAW,IAAI,SAAS,KAAK,OAAO,GAAG,KAAK,eAAe,CAAC;AAC5D,WAAW,IAAI,QAAQ,OAAO,OAAO,GAAG,OAAO,eAAe,CAAC;AAC/D,IAAI,IAAI,cAAc,CAAC;AAGvB,IAAI,IAAI,WAAW,OAAO,CAAC,EAAE,IAAI,WAAW,eAAe,CAAC;AAC5D,IAAI,OAAO,QAAQ,IAAI,QAAQ,MAAM,MAAM;AACzC,UAAQ,IAAI,oBAAK;AACnB,CAAC;","names":["path","process","options","path","i"]}